{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDD assignment\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question-1 Create RDDs in threee different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using parallelize method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "rdd_par = spark.sparkContext.parallelize([\"Hello world\", \"Hope you are bot fed with ABD class\", \"ello\"])\n",
    "print(rdd_par.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello world', 'Hope you are bot fed with ABD class']\n"
     ]
    }
   ],
   "source": [
    "rdd_trans = rdd_par.filter(lambda word: word.startswith('H'))\n",
    "print(rdd_trans.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Lacus suspendisse faucibus interdum posuere lorem ipsum dolor sit amet. Dignissim sodales ut eu sem integer vitae. Dictum at tempor commodo ullamcorper. Non arcu risus quis varius quam. Molestie nunc non blandit massa enim nec. Imperdiet proin fermentum leo vel orci porta. Tortor at risus viverra adipiscing. Nibh praesent tristique magna sit amet. Quis hendrerit dolor magna eget est lorem ipsum. Vitae nunc sed velit dignissim sodales ut eu sem. Laoreet suspendisse interdum consectetur libero id faucibus nisl tincidunt eget. Sed blandit libero volutpat sed cras ornare arcu.', '', 'Odio ut enim blandit volutpat maecenas. Orci a scelerisque purus semper eget duis at tellus. Tellus elementum sagittis vitae et leo. Tincidunt ornare massa eget egestas purus viverra. Mi in nulla posuere sollicitudin aliquam ultrices sagittis. Enim nunc faucibus a pellentesque sit amet. Volutpat blandit aliquam etiam erat velit scelerisque in dictum non. Et tortor at risus viverra. Aliquam id diam maecenas ultricies mi eget. Lacus luctus accumsan tortor posuere. Eros in cursus turpis massa tincidunt dui ut. Auctor neque vitae tempus quam. Tincidunt lobortis feugiat vivamus at augue eget. Ipsum a arcu cursus vitae congue mauris. In eu mi bibendum neque egestas congue quisque. Et leo duis ut diam quam nulla porttitor. Velit dignissim sodales ut eu sem integer vitae justo eget. Vivamus at augue eget arcu dictum varius duis at. Velit dignissim sodales ut eu sem integer vitae justo eget. Faucibus ornare suspendisse sed nisi lacus.', '', 'Nunc sed augue lacus viverra vitae. Est ante in nibh mauris cursus mattis molestie a. Rhoncus est pellentesque elit ullamcorper dignissim cras tincidunt lobortis feugiat. Phasellus egestas tellus rutrum tellus pellentesque eu tincidunt tortor. Dui sapien eget mi proin. In cursus turpis massa tincidunt dui ut ornare. Sit amet luctus venenatis lectus magna fringilla. Fames ac turpis egestas maecenas pharetra convallis posuere morbi. Nec dui nunc mattis enim ut tellus elementum sagittis vitae. Lorem sed risus ultricies tristique nulla aliquet enim tortor. Convallis a cras semper auctor neque vitae tempus quam pellentesque.', '', 'Tortor at auctor urna nunc. Eu nisl nunc mi ipsum faucibus vitae aliquet nec. Nunc eget lorem dolor sed viverra ipsum nunc aliquet. Posuere ac ut consequat semper viverra nam libero. Facilisi nullam vehicula ipsum a arcu. Bibendum at varius vel pharetra vel turpis. Duis ut diam quam nulla. Justo donec enim diam vulputate ut pharetra sit. Proin sagittis nisl rhoncus mattis rhoncus. Amet luctus venenatis lectus magna fringilla. Sit amet nulla facilisi morbi tempus iaculis urna id. Auctor urna nunc id cursus. Id diam maecenas ultricies mi eget mauris pharetra et. Sed risus ultricies tristique nulla aliquet enim tortor at. Nulla malesuada pellentesque elit eget. Et ultrices neque ornare aenean euismod elementum nisi quis. Placerat duis ultricies lacus sed turpis tincidunt id aliquet. Etiam erat velit scelerisque in.', '', 'Bibendum at varius vel pharetra vel. In ornare quam viverra orci sagittis eu volutpat. Aliquet sagittis id consectetur purus ut faucibus pulvinar elementum integer. Sed sed risus pretium quam vulputate dignissim. Ac feugiat sed lectus vestibulum mattis ullamcorper. Laoreet id donec ultrices tincidunt arcu. Platea dictumst quisque sagittis purus sit amet volutpat consequat. Cursus turpis massa tincidunt dui ut ornare lectus sit amet. Adipiscing elit pellentesque habitant morbi tristique senectus et netus et. Duis convallis convallis tellus id interdum. Nulla aliquet porttitor lacus luctus accumsan tortor posuere ac ut.']\n"
     ]
    }
   ],
   "source": [
    "rdd_ds = spark.sparkContext.textFile('input.txt')\n",
    "print(rdd_ds.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a text file and count the number of words in the file using RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the file is 565\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile('input.txt')\n",
    "word_rdd = rdd.flatMap(lambda line : line.split(' '))\n",
    "filtered_word = word_rdd.filter(lambda word : len(word) > 0)\n",
    "print(f'Number of words in the file is {filtered_word.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###\tWrite a program to find the word frequency in a given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ut', 14),\n",
       " ('sed', 10),\n",
       " ('at', 9),\n",
       " ('tincidunt', 8),\n",
       " ('nunc', 7),\n",
       " ('eget', 7),\n",
       " ('vitae', 7),\n",
       " ('eu', 7),\n",
       " ('id', 7),\n",
       " ('eget.', 6),\n",
       " ('ornare', 6),\n",
       " ('sagittis', 6),\n",
       " ('sit', 6),\n",
       " ('risus', 6),\n",
       " ('enim', 6),\n",
       " ('ipsum', 5),\n",
       " ('magna', 5),\n",
       " ('faucibus', 5),\n",
       " ('nulla', 5),\n",
       " ('pellentesque', 5),\n",
       " ('diam', 5),\n",
       " ('mi', 5),\n",
       " ('quam', 5),\n",
       " ('massa', 5),\n",
       " ('viverra', 5),\n",
       " ('a', 5),\n",
       " ('ultricies', 5),\n",
       " ('turpis', 5),\n",
       " ('pharetra', 5),\n",
       " ('amet.', 4),\n",
       " ('sodales', 4),\n",
       " ('varius', 4),\n",
       " ('purus', 4),\n",
       " ('duis', 4),\n",
       " ('in', 4),\n",
       " ('cursus', 4),\n",
       " ('mattis', 4),\n",
       " ('tellus', 4),\n",
       " ('lectus', 4),\n",
       " ('dolor', 4),\n",
       " ('posuere', 4),\n",
       " ('blandit', 4),\n",
       " ('vel', 4),\n",
       " ('tristique', 4),\n",
       " ('dignissim', 4),\n",
       " ('elementum', 4),\n",
       " ('egestas', 4),\n",
       " ('tortor', 4),\n",
       " ('luctus', 4),\n",
       " ('dui', 4),\n",
       " ('neque', 4),\n",
       " ('aliquet', 4),\n",
       " ('consectetur', 3),\n",
       " ('integer', 3),\n",
       " ('Sed', 3),\n",
       " ('cras', 3),\n",
       " ('scelerisque', 3),\n",
       " ('maecenas', 3),\n",
       " ('augue', 3),\n",
       " ('lacus', 3),\n",
       " ('amet', 3),\n",
       " ('convallis', 3),\n",
       " ('urna', 3),\n",
       " ('et', 3),\n",
       " ('suspendisse', 3),\n",
       " ('lorem', 3),\n",
       " ('sem', 3),\n",
       " ('vitae.', 3),\n",
       " ('arcu', 3),\n",
       " ('velit', 3),\n",
       " ('nisl', 3),\n",
       " ('volutpat', 3),\n",
       " ('arcu.', 3),\n",
       " ('semper', 3),\n",
       " ('ultrices', 3),\n",
       " ('Et', 3),\n",
       " ('tempus', 3),\n",
       " ('In', 3),\n",
       " ('elit', 3),\n",
       " ('ac', 3),\n",
       " ('Lorem', 2),\n",
       " ('interdum', 2),\n",
       " ('leo', 2),\n",
       " ('est', 2),\n",
       " ('Laoreet', 2),\n",
       " ('erat', 2),\n",
       " ('dictum', 2),\n",
       " ('ut.', 2),\n",
       " ('lobortis', 2),\n",
       " ('feugiat', 2),\n",
       " ('congue', 2),\n",
       " ('Velit', 2),\n",
       " ('justo', 2),\n",
       " ('at.', 2),\n",
       " ('nisi', 2),\n",
       " ('Nunc', 2),\n",
       " ('Sit', 2),\n",
       " ('venenatis', 2),\n",
       " ('fringilla.', 2),\n",
       " ('Bibendum', 2),\n",
       " ('Duis', 2),\n",
       " ('vulputate', 2),\n",
       " ('et.', 2),\n",
       " ('tempor', 2),\n",
       " ('Lacus', 2),\n",
       " ('ullamcorper.', 2),\n",
       " ('quam.', 2),\n",
       " ('nec.', 2),\n",
       " ('orci', 2),\n",
       " ('Tortor', 2),\n",
       " ('libero', 2),\n",
       " ('Tincidunt', 2),\n",
       " ('viverra.', 2),\n",
       " ('aliquam', 2),\n",
       " ('accumsan', 2),\n",
       " ('Auctor', 2),\n",
       " ('mauris', 2),\n",
       " ('tortor.', 2),\n",
       " ('auctor', 2),\n",
       " ('aliquet.', 2),\n",
       " ('donec', 2),\n",
       " ('morbi', 2),\n",
       " ('Nulla', 2),\n",
       " ('do', 1),\n",
       " ('labore', 1),\n",
       " ('commodo', 1),\n",
       " ('Non', 1),\n",
       " ('quis', 1),\n",
       " ('Molestie', 1),\n",
       " ('fermentum', 1),\n",
       " ('adipiscing.', 1),\n",
       " ('Nibh', 1),\n",
       " ('ipsum.', 1),\n",
       " ('Orci', 1),\n",
       " ('Tellus', 1),\n",
       " ('Mi', 1),\n",
       " ('sollicitudin', 1),\n",
       " ('etiam', 1),\n",
       " ('Aliquam', 1),\n",
       " ('posuere.', 1),\n",
       " ('Ipsum', 1),\n",
       " ('mauris.', 1),\n",
       " ('bibendum', 1),\n",
       " ('quisque.', 1),\n",
       " ('Vivamus', 1),\n",
       " ('lacus.', 1),\n",
       " ('Est', 1),\n",
       " ('ante', 1),\n",
       " ('nibh', 1),\n",
       " ('molestie', 1),\n",
       " ('Rhoncus', 1),\n",
       " ('ullamcorper', 1),\n",
       " ('feugiat.', 1),\n",
       " ('rutrum', 1),\n",
       " ('Dui', 1),\n",
       " ('sapien', 1),\n",
       " ('ornare.', 1),\n",
       " ('Convallis', 1),\n",
       " ('nunc.', 1),\n",
       " ('Posuere', 1),\n",
       " ('sit.', 1),\n",
       " ('Proin', 1),\n",
       " ('rhoncus', 1),\n",
       " ('facilisi', 1),\n",
       " ('iaculis', 1),\n",
       " ('cursus.', 1),\n",
       " ('malesuada', 1),\n",
       " ('aenean', 1),\n",
       " ('quis.', 1),\n",
       " ('volutpat.', 1),\n",
       " ('Aliquet', 1),\n",
       " ('dignissim.', 1),\n",
       " ('quisque', 1),\n",
       " ('consequat.', 1),\n",
       " ('Cursus', 1),\n",
       " ('Adipiscing', 1),\n",
       " ('habitant', 1),\n",
       " ('interdum.', 1),\n",
       " ('porttitor', 1),\n",
       " ('amet,', 1),\n",
       " ('adipiscing', 1),\n",
       " ('elit,', 1),\n",
       " ('eiusmod', 1),\n",
       " ('incididunt', 1),\n",
       " ('dolore', 1),\n",
       " ('aliqua.', 1),\n",
       " ('Dignissim', 1),\n",
       " ('Dictum', 1),\n",
       " ('non', 1),\n",
       " ('Imperdiet', 1),\n",
       " ('proin', 1),\n",
       " ('porta.', 1),\n",
       " ('praesent', 1),\n",
       " ('Quis', 1),\n",
       " ('hendrerit', 1),\n",
       " ('Vitae', 1),\n",
       " ('sem.', 1),\n",
       " ('Odio', 1),\n",
       " ('maecenas.', 1),\n",
       " ('tellus.', 1),\n",
       " ('leo.', 1),\n",
       " ('sagittis.', 1),\n",
       " ('Enim', 1),\n",
       " ('Volutpat', 1),\n",
       " ('non.', 1),\n",
       " ('Eros', 1),\n",
       " ('vivamus', 1),\n",
       " ('porttitor.', 1),\n",
       " ('Faucibus', 1),\n",
       " ('a.', 1),\n",
       " ('Phasellus', 1),\n",
       " ('proin.', 1),\n",
       " ('Fames', 1),\n",
       " ('morbi.', 1),\n",
       " ('Nec', 1),\n",
       " ('pellentesque.', 1),\n",
       " ('Eu', 1),\n",
       " ('consequat', 1),\n",
       " ('nam', 1),\n",
       " ('libero.', 1),\n",
       " ('Facilisi', 1),\n",
       " ('nullam', 1),\n",
       " ('vehicula', 1),\n",
       " ('turpis.', 1),\n",
       " ('nulla.', 1),\n",
       " ('Justo', 1),\n",
       " ('rhoncus.', 1),\n",
       " ('Amet', 1),\n",
       " ('id.', 1),\n",
       " ('Id', 1),\n",
       " ('euismod', 1),\n",
       " ('Placerat', 1),\n",
       " ('Etiam', 1),\n",
       " ('in.', 1),\n",
       " ('vel.', 1),\n",
       " ('pulvinar', 1),\n",
       " ('integer.', 1),\n",
       " ('pretium', 1),\n",
       " ('Ac', 1),\n",
       " ('vestibulum', 1),\n",
       " ('Platea', 1),\n",
       " ('dictumst', 1),\n",
       " ('senectus', 1),\n",
       " ('netus', 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile('input.txt')\n",
    "filtered_lines = rdd.filter(lambda line : line.strip()) # to remove lines that are empty\n",
    "word_rdd = filtered_lines.flatMap(lambda line : line.split(' '))\n",
    "freq_words = word_rdd.map(lambda word : (word, 1))\n",
    "sorted(freq_words.reduceByKey(lambda a,b : a + b).collect(),\n",
    "      key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a program to convert all words in a file to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile('input.txt')\n",
    "converted_rdd = rdd.flatMap(lambda line : line.split(' '))\n",
    "converted_rdd = rdd.map(lambda line : line.upper())\n",
    "with open('UppercaseFile.txt', 'w') as f:\n",
    "    for line in converted_rdd.collect():\n",
    "        f.write(f'{line}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a program to convert all words in a file to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile('input.txt')\n",
    "converted_rdd = rdd.flatMap(lambda line : line.split(' '))\n",
    "converted_rdd = rdd.map(lambda line : line.lower())\n",
    "with open('LowercaseFile.txt', 'w') as f:\n",
    "    for line in converted_rdd.collect():\n",
    "        f.write(f'{line}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a program to capitalize first letter of each words in file (use string capitalize() method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.sparkContext.textFile('input.txt')\n",
    "converted_rdd = rdd.flatMap(lambda line : line.split(' '))\n",
    "converted_rdd = converted_rdd.map(lambda word : word.capitalize())\n",
    "with open('HeadingcaseFile.txt', 'w') as f:\n",
    "    for line in converted_rdd.collect():\n",
    "        f.write(f'{line}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the longest length of word from given set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length word is vulputate with length 9\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile('input.txt')\n",
    "word_rdd = rdd.flatMap(lambda line : line.split(' '))\n",
    "max_word = word_rdd.max()\n",
    "print(f'Max length word is {max_word} with length {len(max_word)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the Registration numbers to corresponding branch. \n",
    "\n",
    "* 1000 series ML\n",
    "* 2000 series VLSI\n",
    "* 3000 series ES\n",
    "* 4000 series MSc\n",
    "* 5000 series CC\n",
    "* 6000 series BDA\n",
    "* 9000 series HDA\n",
    "\n",
    "Given registration number, generate a key-value pair of Registration Number and Corresponding Branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# before running please delete the regProg folder\n",
    "program = {\n",
    "    1: 'ML', 2: 'VLSI', 3: 'ES', 4: 'MSc', 5: 'CC', 6: 'BDA', 9: 'HDA'\n",
    "}\n",
    "\n",
    "rdd = spark.sparkContext.textFile('reg.txt')\n",
    "reg_rdd = rdd.map(lambda x : (x, program[int(x) // 1000]) if int(x) // 1000 in program else (x, np.nan))\n",
    "reg_rdd.collect()\n",
    "reg_rdd.saveAsTextFile('regProg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text file contain numbers. Numbers are separated by one white space. There is no order to store the numbers. One line may contain one or more numbers.\n",
    "Find the maximum, minimum, sum and mean of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number = 2212.1\n",
      "Min number = 1.7\n",
      "Sum of numbers = 522656.4200000001\n",
      "Mean of numbers = 519.5391848906563\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile('numbers.txt')\n",
    "text_num_rdd = rdd.flatMap(lambda x : x.split(' '))\n",
    "num_rdd = text_num_rdd.map(lambda x : float(x))\n",
    "max_num = num_rdd.max()\n",
    "min_num = num_rdd.min()\n",
    "sum_num = num_rdd.sum()\n",
    "mean_num = num_rdd.mean()\n",
    "print(f'Max number = {max_num}')\n",
    "print(f'Min number = {min_num}')\n",
    "print(f'Sum of numbers = {sum_num}')\n",
    "print(f'Mean of numbers = {mean_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A text file (citizen.txt) contains data about citizens of country. Fields (information in file) are Name, dob, Phone, email and state name. Another file contains mapping of state names to state code like Karnataka is codes as KA, TamilNadu as TN, Kerala KL etc. Compress the citizen.txt file by changing full state name to state code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\pyspark\\sql\\dataframe.py:1894: UserWarning: to_replace is a dict and value is not None. value will be ignored.\n",
      "  warnings.warn(\"to_replace is a dict and value is not None. value will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "# Remove compressed_citizen_df before running\n",
    "state_mapping = spark.read.csv(\"state_mapping.txt\", inferSchema=True, header=True)\n",
    "state_mapping = map(lambda row : row.asDict(), state_mapping.collect())\n",
    "state_mapping = {state['state']: state['statecode'] for state in state_mapping}\n",
    "\n",
    "citizen_df = spark.read.csv(\"citizen.txt\", inferSchema=True, header=True)\n",
    "updated_citizen_df = citizen_df.na.replace(state_mapping, 1)\n",
    "updated_citizen_df.write.csv('compressed_citizen_df', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
